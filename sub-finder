#!/usr/bin/env python3
# Author: iamsurve

import requests
from bs4 import BeautifulSoup
import argparse
import time
from rich.console import Console
from rich.table import Table
from rich.progress import Progress
from rich.panel import Panel

# Initialize rich console
console = Console()

def fetch_subdomains_from_google(domain, max_results=50):
    """
    Fetch subdomains of a given domain from Google search results.
    
    Args:
        domain (str): The target domain (e.g., "example.com").
        max_results (int, optional): Maximum number of results to fetch. Defaults to 50.
    
    Returns:
        list: A list of discovered subdomains.
    """
    subdomains = set()
    query = f"site:{domain}"
    url = f"https://www.google.com/search?q={query}&num={max_results}"
    
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
    }
    
    try:
        with Progress() as progress:
            task = progress.add_task("[cyan]Fetching subdomains from Google...", total=1)
            response = requests.get(url, headers=headers, timeout=10)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.text, "html.parser")
            for link in soup.find_all("a"):
                href = link.get("href")
                if href.startswith("/url?q="):
                    href = href.split("/url?q=")[1].split("&")[0]
                    if domain in href:
                        subdomain = href.split("://")[-1].split("/")[0].split(f".{domain}")[0]
                        if subdomain and subdomain != domain:
                            subdomains.add(subdomain)
            progress.update(task, advance=1)
            time.sleep(2)  # Respectful delay to avoid rate-limiting
        
    except requests.exceptions.RequestException as e:
        console.print(f"[red][-] Error fetching Google results: {e}")
    
    return list(subdomains)

def check_common_subdomains(domain, common_subdomains):
    """
    Check a list of common subdomains for the given domain.
    
    Args:
        domain (str): The target domain (e.g., "example.com").
        common_subdomains (list): List of common subdomains to check.
    
    Returns:
        list: A list of discovered subdomains.
    """
    discovered = []
    with Progress() as progress:
        task = progress.add_task("[cyan]Checking common subdomains...", total=len(common_subdomains))
        for subdomain in common_subdomains:
            url = f"https://{subdomain}.{domain}"
            try:
                response = requests.get(url, timeout=5)
                if response.status_code == 200:
                    discovered.append(f"{subdomain}.{domain}")
            except requests.exceptions.RequestException:
                pass
            progress.update(task, advance=1)
    return discovered

def save_results(subdomains, output_file):
    """
    Save the discovered subdomains to a file.
    
    Args:
        subdomains (list): List of subdomains.
        output_file (str): File to save the results.
    """
    with open(output_file, "w") as f:
        for subdomain in subdomains:
            f.write(f"{subdomain}\n")

if __name__ == "__main__":
    # Banner
    console.print(Panel.fit("[bold green]Subdomain Finder[/bold green]", title="[blue]Author: iamsurve[/blue]"))
    
    # Parse arguments
    parser = argparse.ArgumentParser(description="Fetch subdomains of a domain.")
    parser.add_argument("-d", "--domain", required=True, help="Target domain (e.g., example.com)")
    parser.add_argument("-o", "--output", default="subdomains.txt", help="Output file to save results")
    args = parser.parse_args()
    
    domain = args.domain
    output_file = args.output
    
    # Common subdomains to check
    common_subdomains = ["www", "mail", "ftp", "admin", "blog", "dev", "test", "api", "secure"]
    
    # Fetch subdomains
    console.print(f"[bold yellow][*] Scanning subdomains for {domain}...[/bold yellow]")
    
    # Fetch from Google
    google_subdomains = fetch_subdomains_from_google(domain)
    
    # Check common subdomains
    common_discovered = check_common_subdomains(domain, common_subdomains)
    
    # Combine results
    all_subdomains = list(set(google_subdomains + common_discovered))
    
    # Display results
    if all_subdomains:
        table = Table(title=f"[bold green]Discovered Subdomains for {domain}[/bold green]")
        table.add_column("Subdomain", style="cyan")
        for subdomain in all_subdomains:
            table.add_row(subdomain)
        console.print(table)
        
        # Save results
        save_results(all_subdomains, output_file)
        console.print(f"[bold green][+] Results saved to {output_file}[/bold green]")
    else:
        console.print("[bold red][-] No subdomains found.[/bold red]")
